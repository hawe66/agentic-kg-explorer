## 피드백 1) 지금 상태에선 “retrieval_type이 분기마다 제대로 된다”고 보기 어렵다
### 근거(로그 기반)
#### 케이스 A: `"parameter based learning"`* `intent: "expansion"`* 실제 행동: `vector_results`가 채워졌고, `cypher_executed: ["(vector enrichment)"]`이며 `kg_results`도 존재 → **Vector로 seed를 찾고 Graph로 확장한 Hybrid 실행**입니다.여기서 retrieval_type이 만약:* `retrieval_type="expansion"` (intent를 그대로 넣는 방식) 이라면 **명백히 틀림** * 이유: expansion은 “질문의 유형”이고 retrieval_type은 “데이터 획득 방식”이기 때문.* `retrieval_type="vector"` (vector만 했다고 기록) 이라면 **정의에 따라 반쯤 틀림** * 실제로는 vector만이 아니라 graph enrichment도 했으므로, “최종 컨텍스트 구성 방식” 관점에선 틀립니다.즉, 이 케이스는 **retrieval_type을 ‘의도(intent)’ 또는 ‘첫 단계(vector)’로만 표현하면 실제 실행과 불일치**가 발생하는 대표 사례입니다.

---

## 피드백 2) retrieval_type이 “맞을 수도” 있는 조건과 “틀릴 수밖에 없는” 조건retrieval_type이 무엇을 의미하느냐에 따라 판정이 갈립니다. 지금 시스템처럼 hybrid가 존재하면 특히요.### ✅ retrieval_type이 “맞다”가 성립하려면 (정의가 명확해야 함)아래 둘 중 하나로 정의를 고정해야 합니다.1. **Seed 기준 정의*** retrieval_type = “첫 retrieval의 방식”* 예: parameter based learning → `vector` (seed는 vector니까)* 장점: 분류 단순* 단점: hybrid의 실제 실행(그래프 확장)을 가린다 → 디버깅/평가에 불리2. **Final context 기준 정의(추천)*** retrieval_type = “최종 답변 컨텍스트를 구성한 방식”* 예: parameter based learning → `hybrid_vector_graph`* 장점: 실행을 정확히 반영, 평가(모드 효용성)에도 직접 사용 가능* 단점: 조금 더 복잡하지만, 지금은 이게 필요함---
### ❌ retrieval_type이 “틀릴 수밖에 없는” 구조 (자주 나오는 버그 패턴)아래 중 하나면 분기마다 값이 어긋날 확률이 큽니다.* **(패턴 1) retrieval_type을 intent에서 파생** * expansion/comparison 같은 “질문 의도”를 retrieval_type에 넣음 * → 당신이 말한 “intent는 expansion인데 행동은 vector” 문제랑 똑같이 메타가 깨집니다.* **(패턴 2) fallback/hybrid가 발생해도 retrieval_type을 갱신하지 않음** * 예: graph branch로 들어가 `retrieval_type="graph"` 찍고, 결과가 없으니 vector fallback 실행 * 그런데 retrieval_type은 그대로 graph * → 로그상으로는 vector_results가 있는데 retrieval_type이 graph로 남는 식의 모순이 생김* **(패턴 3) vector enrichment를 “graph 사용”으로 카운트하지 않음** * `(vector enrichment)`도 결국 cypher/neo4j 호출인데 * 이를 graph 사용으로 기록하지 않으면 hybrid가 vector-only처럼 보입니다.

---
## 피드백 3) 지금 로그 기준으로 “올바른 retrieval_type(추천)”은 이렇게 나뉘어야 함당신 로그 구조(`vector_results`, `cypher_executed`, `kg_results`)를 보면, retrieval_type은 실행 후 **관측값 기반으로 자동 결정**하는 게 가장 안전합니다.
### 추천 규칙(“실행 결과로부터” 산출)* `used_vector = len(vector_results) > 0`* `used_graph = len(cypher_executed) > 0` *(“(vector enrichment)”도 포함해서 True)** `used_web = web_search_executed == True` (있다면)그럼:* used_web and (used_vector or used_graph) → `hybrid_web_*`* used_vector and used_graph → `hybrid_vector_graph`* used_graph only → `graph_only`* used_vector only → `vector_only`* 아무 것도 없으면 → `none` (그리고 답변은 “데이터 없음/질문 уточ”로 가야 함)이 규칙이면,* `"parameter based learning"` 케이스는 **무조건 `hybrid_vector_graph`**가 됩니다. (지금 행동과 일치)---## 피드백 4) 제안: retrieval_type을 1개만 두지 말고 2개로 분리하세요 (강추)당신이 겪는 혼란이 “의도 vs 행동” 혼선이었잖아요. retrieval도 똑같습니다.* `retrieval_plan` : 의도/라우터가 “원래 하려던 모드” * 예: expansion → (원칙상) web or vector_only 등* `retrieval_actual` : 실제 실행된 모드(관측값 기반) * 예: vector + graph enrichment → hybrid_vector_graph이렇게 두면,* intent는 expansion이어도 **plan=web, actual=hybrid** 같은 “불일치”가 **관찰 가능한 신호**가 됩니다.* 지금처럼 “expansion인데 웹 없이 vector로 해결”을 시스템이 스스로 감지할 수 있어요.

---
## 피드백 5) 최소 코드 구조(예시) — “분기에서 세팅하지 말고, 실행 후 결정”아래처럼 “분기마다 retrieval_type을 직접 할당”하지 말고, **실행된 step을 기록한 뒤 마지막에 derive**하세요.
```pythonfrom dataclasses import dataclass, fieldfrom typing import List, Dict, Optional@dataclassclass RetrievalTrace: steps: List[Dict] = field(default_factory=list) vector_results: List[Dict] = field(default_factory=list) cypher_executed: List[str] = field(default_factory=list) web_used: bool = Falsedef derive_retrieval_type(t: RetrievalTrace) -> str: used_vector = len(t.vector_results) > 0 used_graph = len(t.cypher_executed) > 0 used_web = t.web_used if used_web and (used_vector or used_graph): return "hybrid_web" if used_vector and used_graph: return "hybrid_vector_graph" if used_graph: return "graph_only" if used_vector: return "vector_only" if used_web: return "web_only" return "none"```이러면 “분기에서 무엇을 할당했는지”에 의존하지 않고 **실행과 메타가 항상 일치**합니다.

---
# 결론 (한 줄 판정)* **코드를 직접 보진 못했지만**, 지금 공유한 실행 로그를 근거로 보면 **retrieval_type이 분기마다 ‘정확하게’ 기록되고 있다고 보기 어렵고**, 특히 **Hybrid(=vector+graph enrichment)**가 있는 구조에서는 “분기에서 값 할당” 방식이 거의 항상 메타 불일치를 만든다고 보는 게 합리적입니다.