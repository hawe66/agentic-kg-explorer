# Phase 5: Prompt Optimizer â€” Design Document

> Phase 5ëŠ” Critic Agentì˜ í‰ê°€ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ìë™ ìµœì í™”í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•œë‹¤.
> Human-in-the-Loop ì´ì¤‘ ê²Œì´íŠ¸ë¡œ ì•ˆì „í•˜ê²Œ í”„ë¡¬í”„íŠ¸ ì§„í™”ë¥¼ ê´€ë¦¬í•œë‹¤.

---

## 1. ëª©í‘œ ìš”ì•½

1. **Failure Analyzer** â€” ë°˜ë³µ ì‹¤íŒ¨ íŒ¨í„´ íƒì§€ ë° FailurePattern ìƒì„±
2. **Variant Generator** â€” ì‹¤íŒ¨ ê°€ì„¤ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ë³€í˜• ìƒì„± (3ê°œ)
3. **Test Runner** â€” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë¡œ ë³€í˜• í‰ê°€, ìµœê³  ì„±ëŠ¥ ì„ íƒ
4. **Prompt Registry** â€” í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬, í™œì„±í™”/ë¡¤ë°±
5. **Review UI** â€” Human-in-the-Loop ìŠ¹ì¸ ê²Œì´íŠ¸

---

## 2. ì „ì²´ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     EVALUATION ACCUMULATION                      â”‚
â”‚  Phase 4 Critic â†’ Evaluation nodes in Neo4j (NíšŒ ì¶•ì )           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                         trigger (N >= threshold)
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FAILURE ANALYZER                             â”‚
â”‚  - Query low-scoring evaluations by agent                        â”‚
â”‚  - Cluster by criterion (ec:source-citation, ec:reasoning, etc.) â”‚
â”‚  - Generate FailurePattern with root_cause_hypotheses            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     GATE 1: HYPOTHESIS REVIEW                    â”‚
â”‚  User reviews/edits root_cause_hypotheses before proceeding      â”‚
â”‚  Options: Approve / Edit / Reject / Add more hypotheses          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                         (approved)
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     VARIANT GENERATOR                            â”‚
â”‚  - Load current prompt for affected agent                        â”‚
â”‚  - LLM generates 3 prompt variants addressing hypotheses         â”‚
â”‚  - Each variant has: diff, rationale, expected_improvement       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     TEST RUNNER                                  â”‚
â”‚  - Run test queries (from config/test_queries.yaml)              â”‚
â”‚  - Evaluate each variant with Critic                             â”‚
â”‚  - Compare composite scores vs baseline                          â”‚
â”‚  - Rank variants by performance_delta                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     GATE 2: PROMPT APPROVAL                      â”‚
â”‚  User reviews best variant:                                      â”‚
â”‚  - Side-by-side diff with current prompt                         â”‚
â”‚  - Test results summary                                          â”‚
â”‚  - Options: Approve / Edit / Reject / Try another variant        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                         (approved)
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PROMPT REGISTRY                              â”‚
â”‚  - Create PromptVersion node in Neo4j                            â”‚
â”‚  - Link: (PromptVersion)-[:ADDRESSES]->(FailurePattern)          â”‚
â”‚  - Set is_active=true, deactivate previous version               â”‚
â”‚  - Update prompt file on disk                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Graph Schema (ì´ë¯¸ Phase 4ì—ì„œ ì¶”ê°€ë¨)

```cypher
// FailurePattern: ë°˜ë³µ ì‹¤íŒ¨ íŒ¨í„´
CREATE CONSTRAINT fp_id IF NOT EXISTS
FOR (fp:FailurePattern) REQUIRE fp.id IS UNIQUE;

CREATE INDEX fp_type IF NOT EXISTS
FOR (fp:FailurePattern) ON (fp.pattern_type);

// PromptVersion: í”„ë¡¬í”„íŠ¸ ë²„ì „
CREATE CONSTRAINT pv_id IF NOT EXISTS
FOR (pv:PromptVersion) REQUIRE pv.id IS UNIQUE;

CREATE INDEX pv_agent IF NOT EXISTS
FOR (pv:PromptVersion) ON (pv.agent_name);

CREATE INDEX pv_active IF NOT EXISTS
FOR (pv:PromptVersion) ON (pv.is_active);

// Relationships
// (FailurePattern)-[:IDENTIFIED_FROM]->(Evaluation)
// (PromptVersion)-[:ADDRESSES]->(FailurePattern)
// (PromptVersion)-[:PARENT_OF]->(PromptVersion)
```

### Node Properties

```yaml
FailurePattern:
  id: string              # "fp:synthesizer:source-citation:2026-02"
  pattern_type: string    # "output_quality" | "reasoning" | "retrieval" | "classification"
  agent_name: string      # "synthesizer"
  criterion_id: string    # "ec:source-citation"
  description: string     # "Synthesizer consistently fails to cite KG sources"
  frequency: int          # Number of low-score evaluations
  sample_queries: [string] # Example queries that triggered this
  avg_score: float        # Average score for this criterion
  root_cause_hypotheses: [string]  # LLM-generated hypotheses
  suggested_fixes: [string]        # Potential prompt changes
  status: string          # "detected" | "reviewing" | "addressing" | "resolved"
  created_at: datetime
  resolved_at: datetime

PromptVersion:
  id: string              # "pv:synthesizer@1.2.0"
  agent_name: string      # "synthesizer"
  version: string         # "1.2.0" (semver)
  prompt_hash: string     # SHA256 of prompt content
  prompt_path: string     # "prompts/synthesizer/v1.2.0.txt"
  is_active: boolean      # Only one active per agent
  user_approved: boolean  # Human approved this version
  parent_version: string  # "pv:synthesizer@1.1.0"
  performance_delta: float # +0.05 improvement from parent
  test_results: string    # JSON summary of test run
  rationale: string       # Why this change was made
  created_at: datetime
  approved_at: datetime
  approved_by: string     # User identifier
```

---

## 4. íŒŒì¼ êµ¬ì¡°

```
src/
â”œâ”€â”€ optimizer/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ analyzer.py       # FailureAnalyzer class
â”‚   â”œâ”€â”€ generator.py      # VariantGenerator class
â”‚   â”œâ”€â”€ runner.py         # TestRunner class
â”‚   â”œâ”€â”€ registry.py       # PromptRegistry class
â”‚   â””â”€â”€ models.py         # Dataclasses (FailurePattern, PromptVariant, etc.)
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py            # Add optimization review panels
config/
â”œâ”€â”€ test_queries.yaml     # Test queries per intent type
â””â”€â”€ prompts/              # Versioned prompt storage
    â”œâ”€â”€ synthesizer/
    â”‚   â”œâ”€â”€ current.txt   # Symlink to active version
    â”‚   â”œâ”€â”€ v1.0.0.txt
    â”‚   â””â”€â”€ v1.1.0.txt
    â”œâ”€â”€ intent_classifier/
    â””â”€â”€ search_planner/
scripts/
â”œâ”€â”€ analyze_failures.py   # CLI to trigger failure analysis
â”œâ”€â”€ generate_variants.py  # CLI to generate prompt variants
â””â”€â”€ run_optimization.py   # Full optimization pipeline
```

---

## 5. ì»´í¬ë„ŒíŠ¸ ìƒì„¸

### 5.1 Failure Analyzer (`src/optimizer/analyzer.py`)

```python
class FailureAnalyzer:
    """Detect recurring failure patterns from evaluations."""

    def __init__(self, threshold: float = 0.6, min_samples: int = 5):
        self.threshold = threshold  # Score below this = failure
        self.min_samples = min_samples  # Min failures to create pattern

    def analyze(self, agent_name: str = None) -> list[FailurePattern]:
        """Query evaluations, cluster failures, generate patterns."""
        # 1. Query low-scoring evaluations from Neo4j
        # 2. Group by (agent_name, criterion_id)
        # 3. For groups with count >= min_samples:
        #    - Generate FailurePattern
        #    - Use LLM to hypothesize root causes
        # 4. Save FailurePattern to Neo4j
        pass

    def _generate_hypotheses(
        self,
        agent_name: str,
        criterion: str,
        sample_queries: list[str],
        sample_responses: list[str],
    ) -> list[str]:
        """Use LLM to generate root cause hypotheses."""
        prompt = f"""
        The {agent_name} agent consistently scores low on "{criterion}".

        Sample failing queries and responses:
        {self._format_samples(sample_queries, sample_responses)}

        Generate 2-3 hypotheses for why this might be happening.
        Focus on prompt-level issues that could be fixed.

        Output as JSON list: ["hypothesis 1", "hypothesis 2", ...]
        """
        # LLM call
        pass
```

### 5.2 Variant Generator (`src/optimizer/generator.py`)

```python
class VariantGenerator:
    """Generate prompt variants to address failure patterns."""

    def generate_variants(
        self,
        failure_pattern: FailurePattern,
        num_variants: int = 3,
    ) -> list[PromptVariant]:
        """Generate prompt variants addressing the failure."""
        # 1. Load current prompt for agent
        current_prompt = self._load_current_prompt(failure_pattern.agent_name)

        # 2. Generate variants with LLM
        prompt = f"""
        Current prompt for {failure_pattern.agent_name}:
        ---
        {current_prompt}
        ---

        This prompt has a recurring issue: {failure_pattern.description}

        Root cause hypotheses:
        {failure_pattern.root_cause_hypotheses}

        Generate {num_variants} improved versions of this prompt.
        Each version should:
        1. Address at least one hypothesis
        2. Be a complete replacement prompt
        3. Include a brief rationale

        Output as JSON:
        [
          {{
            "prompt": "full new prompt text...",
            "rationale": "why this change helps",
            "addresses_hypotheses": [0, 1]
          }},
          ...
        ]
        """
        # LLM call, parse variants
        pass
```

### 5.3 Test Runner (`src/optimizer/runner.py`)

```python
class TestRunner:
    """Run test queries and evaluate prompt variants."""

    def __init__(self):
        self.evaluator = get_evaluator()

    def run_tests(
        self,
        agent_name: str,
        variants: list[PromptVariant],
        test_queries: list[str] = None,
    ) -> list[TestResult]:
        """Run tests for each variant, return ranked results."""
        if test_queries is None:
            test_queries = self._load_test_queries(agent_name)

        results = []

        # Test baseline (current prompt)
        baseline_scores = self._test_variant(agent_name, None, test_queries)

        # Test each variant
        for variant in variants:
            variant_scores = self._test_variant(agent_name, variant, test_queries)
            delta = self._calculate_delta(baseline_scores, variant_scores)

            results.append(TestResult(
                variant=variant,
                scores=variant_scores,
                baseline_scores=baseline_scores,
                performance_delta=delta,
            ))

        # Rank by performance delta
        results.sort(key=lambda r: r.performance_delta, reverse=True)
        return results

    def _test_variant(
        self,
        agent_name: str,
        variant: PromptVariant | None,
        test_queries: list[str],
    ) -> dict[str, float]:
        """Run test queries with a specific prompt variant."""
        # Temporarily swap prompt if variant provided
        # Run queries through pipeline
        # Collect evaluation scores
        # Return average scores per criterion
        pass
```

### 5.4 Prompt Registry (`src/optimizer/registry.py`)

```python
class PromptRegistry:
    """Manage prompt versions and activation."""

    def __init__(self, prompts_dir: Path = None):
        self.prompts_dir = prompts_dir or Path("config/prompts")

    def get_current_version(self, agent_name: str) -> PromptVersion:
        """Get currently active prompt version."""
        pass

    def get_version_history(self, agent_name: str) -> list[PromptVersion]:
        """Get all versions for an agent."""
        pass

    def create_version(
        self,
        agent_name: str,
        content: str,
        parent_version: str,
        failure_pattern_id: str,
        rationale: str,
        test_results: dict,
    ) -> PromptVersion:
        """Create new prompt version (not yet active)."""
        # 1. Calculate next version number
        # 2. Write prompt to file
        # 3. Create PromptVersion node in Neo4j
        # 4. Link to FailurePattern
        pass

    def activate_version(self, version_id: str, approved_by: str) -> bool:
        """Activate a prompt version (deactivate previous)."""
        # 1. Set is_active=false on current active
        # 2. Set is_active=true, user_approved=true on new version
        # 3. Update symlink: current.txt -> vX.Y.Z.txt
        pass

    def rollback(self, agent_name: str, to_version: str = None) -> bool:
        """Rollback to previous version."""
        # If to_version not specified, rollback to parent
        pass
```

---

## 6. Test Queries Configuration

```yaml
# config/test_queries.yaml

synthesizer:
  - query: "What is ReAct?"
    expected_intent: lookup
    expected_entities: ["m:react"]
    min_confidence: 0.7

  - query: "What methods address Planning?"
    expected_intent: path
    min_sources: 2

  - query: "Compare LangChain and CrewAI"
    expected_intent: comparison
    expected_entities: ["impl:langchain", "impl:crewai"]

intent_classifier:
  - query: "What is CoT?"
    expected_intent: lookup
    expected_entities: ["m:cot"]

  - query: "How many methods are there?"
    expected_intent: aggregation

  - query: "What's the weather?"
    expected_intent: out_of_scope

search_planner:
  - query: "Which frameworks implement ReAct?"
    expected_template: "path_method_to_impl"
    expected_retrieval: "hybrid"

graph_retriever:
  - query: "What is ReAct?"
    min_results: 1
    no_error: true
```

---

## 7. UI Components (âœ… êµ¬í˜„ ì™„ë£Œ)

> ì•„ë˜ëŠ” `src/ui/app.py`ì— êµ¬í˜„ëœ Streamlit UI êµ¬ì„±ìš”ì†Œ ì„¤ëª…ì´ë‹¤.

### 7.1 Failure Patterns Panel (Sidebar)

ì‚¬ì´ë“œë°” "Prompt Optimizer" ì„¹ì…˜ì˜ `ğŸ”§ Failure Patterns` expander ë‚´ë¶€:

- **Analyze Failures** ë²„íŠ¼ â†’ `FailureAnalyzer(threshold=0.6).analyze()` í˜¸ì¶œ
- íƒì§€ëœ íŒ¨í„´ ëª©ë¡: agent ì´ë¦„, criterion, frequency, avg score (ìƒ‰ìƒ ì½”ë”©)
- ê° íŒ¨í„´ì— **Start Optimization** ë²„íŠ¼ â†’ Gate 1ìœ¼ë¡œ ì „í™˜
- **ğŸ“œ Version History** ë²„íŠ¼ â†’ ë²„ì „ ì´ë ¥ íŒ¨ë„ ì—´ê¸°

### 7.2 Gate 1: Hypothesis Review Panel

ë©”ì¸ ì˜ì—­ì— `ğŸ”¬ Gate 1: Review Hypotheses` expanderë¡œ í‘œì‹œ:

- íŒ¨í„´ ìš”ì•½: agent, criterion, description, frequency, avg score
- Sample failing queries (ì ‘ê¸° ê°€ëŠ¥)
- **í¸ì§‘ ê°€ëŠ¥í•œ ê°€ì„¤ ëª©ë¡** (`st.text_input` per hypothesis)
- ìƒˆ ê°€ì„¤ ì¶”ê°€ ì…ë ¥ë€
- ì•¡ì…˜ ë²„íŠ¼:
  - **âœ… Approve & Generate Variants** â†’ ê°€ì„¤ ì—…ë°ì´íŠ¸ â†’ `VariantGenerator.generate_variants()` â†’ `TestRunner.run_tests()` â†’ Gate 2 ì „í™˜
  - **âŒ Reject Pattern** â†’ íŒ¨í„´ resolved ì²˜ë¦¬, ìƒíƒœ ì´ˆê¸°í™”

### 7.3 Gate 2: Prompt Approval Panel

ë©”ì¸ ì˜ì—­ì— `ğŸ¯ Gate 2: Approve Prompt Change` expanderë¡œ í‘œì‹œ:

- ì„±ëŠ¥ ìˆœ ì •ë ¬ëœ ë³€í˜• ëª©ë¡ (ğŸ† í‘œì‹œë¡œ ìµœê³  ì„±ëŠ¥ ê°•ì¡°)
- ê° ë³€í˜•:
  - Performance delta (ìƒ‰ìƒ ì½”ë”©), pass rate, passed/failed count
  - Rationale ì„¤ëª…
  - **ğŸ“‹ View Prompt Diff** â€” í˜„ì¬ vs ì œì•ˆ í”„ë¡¬í”„íŠ¸ side-by-side `st.code` ë¹„êµ
  - ë¹„ìµœê³  ë³€í˜•ì— **Select Variant** ë²„íŠ¼ (ìˆœì„œ ì¬ë°°ì¹˜)
- ì•¡ì…˜ ë²„íŠ¼:
  - **âœ… Approve & Activate** â†’ `VariantGenerator.apply_variant()` â†’ `PromptRegistry.activate_version()` â†’ íŒ¨í„´ resolved
  - **ğŸ”„ Re-run Tests** â†’ ë™ì¼ ë³€í˜• ì¬í…ŒìŠ¤íŠ¸
  - **âŒ Reject All** â†’ ìƒíƒœ ì´ˆê¸°í™”

### 7.4 Version History Panel

ë©”ì¸ ì˜ì—­ì— `ğŸ“œ Prompt Version History` expanderë¡œ í‘œì‹œ:

- Agent ì„ íƒ ë“œë¡­ë‹¤ìš´ (synthesizer, intent_classifier, search_planner, graph_retriever)
- ë²„ì „ë³„: version ë²ˆí˜¸, ğŸŸ¢ ACTIVE í‘œì‹œ, performance delta, approved ë‚ ì§œ, rationale
- ë¹„í™œì„± ë²„ì „ì— **âª Rollback** ë²„íŠ¼
- **Close History** ë²„íŠ¼

### 7.5 Session State (Optimizer)

```python
optimizer_patterns: list          # íƒì§€ëœ failure patterns
optimizer_selected_pattern: obj   # Gate 1ì—ì„œ ì„ íƒëœ íŒ¨í„´
optimizer_edited_hypotheses: list # í¸ì§‘ëœ ê°€ì„¤ ëª©ë¡
optimizer_variants: list          # ìƒì„±ëœ prompt variants
optimizer_test_results: list      # í…ŒìŠ¤íŠ¸ ê²°ê³¼
optimizer_gate: str | None        # None | "gate1" | "gate2"
optimizer_show_history: bool      # ë²„ì „ ì´ë ¥ íŒ¨ë„ í‘œì‹œ ì—¬ë¶€
```

---

## 8. êµ¬í˜„ ìˆœì„œ

### Step 1: Models & Registry âœ…
- [x] `src/optimizer/models.py` â€” Dataclasses
- [x] `src/optimizer/registry.py` â€” PromptRegistry
- [x] `config/prompts/` â€” Initial prompt files extracted from code

### Step 2: Failure Analyzer âœ…
- [x] `src/optimizer/analyzer.py` â€” FailureAnalyzer
- [x] `scripts/analyze_failures.py` â€” CLI tool

### Step 3: Variant Generator âœ…
- [x] `src/optimizer/generator.py` â€” VariantGenerator
- [x] `config/test_queries.yaml` â€” Test query definitions

### Step 4: Test Runner âœ…
- [x] `src/optimizer/runner.py` â€” TestRunner
- [x] Integration with Critic evaluator

### Step 5: UI Integration âœ…
- [x] Gate 1: Hypothesis review panel
- [x] Gate 2: Prompt approval panel
- [x] Failure patterns sidebar
- [x] Version history panel with rollback

### Step 6: API Endpoints âœ…
- [x] 7 REST endpoints (`/optimizer/*`)
- [x] Pydantic schemas (`src/api/schemas.py`)

---

## 9. API Endpoints (âœ… êµ¬í˜„ ì™„ë£Œ)

`src/api/routes.py`ì— êµ¬í˜„ëœ 7ê°œ ì—”ë“œí¬ì¸íŠ¸:

| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/optimizer/patterns` | ì‹¤íŒ¨ íŒ¨í„´ ëª©ë¡ (agent, status í•„í„°) |
| `POST` | `/optimizer/analyze` | ì‹¤íŒ¨ íŒ¨í„´ íƒì§€ íŠ¸ë¦¬ê±° |
| `POST` | `/optimizer/patterns/{id}/approve` | Gate 1: ê°€ì„¤ ìŠ¹ì¸ â†’ ë³€í˜• ìƒì„± |
| `POST` | `/optimizer/test` | ë³€í˜• í…ŒìŠ¤íŠ¸ ì‹¤í–‰ |
| `POST` | `/optimizer/versions/{id}/activate` | Gate 2: í”„ë¡¬í”„íŠ¸ ë²„ì „ í™œì„±í™” |
| `POST` | `/optimizer/rollback` | ì´ì „ ë²„ì „ìœ¼ë¡œ ë¡¤ë°± |
| `GET` | `/optimizer/versions` | Agentë³„ ë²„ì „ ì´ë ¥ ì¡°íšŒ |

### Pydantic Schemas (`src/api/schemas.py`)

**Request models:**
- `AnalyzeRequest` â€” agent (optional), threshold (default 0.6)
- `ApproveHypothesesRequest` â€” hypotheses (list[str])
- `TestVariantsRequest` â€” agent_name, pattern_id, variant_ids
- `ActivateVersionRequest` â€” approved_by (default "user")
- `RollbackRequest` â€” agent_name, to_version (optional)

**Response models:**
- `FailurePatternsResponse` â€” patterns list + count
- `GenerateVariantsResponse` â€” variants list + pattern_id
- `TestResultsResponse` â€” results list + best_variant_id
- `VersionHistoryResponse` â€” versions list + current_version + count

---

## 10. ë¦¬ìŠ¤í¬ & ì™„í™”

| Risk | Mitigation |
|------|------------|
| LLM generates poor variants | Human review gate before activation |
| Test queries not representative | Maintain diverse test set, allow user additions |
| Regression after activation | Easy rollback, track performance_delta |
| Over-optimization (overfitting) | Cross-validation with held-out queries |
| Prompt drift over versions | Version history, parent tracking, diff view |

---

## 11. ì´ë¡ ì  ê¸°ë°˜

| Paper | Key Idea | Our Application |
|-------|----------|-----------------|
| **APO** [Pryzant 2023] | Text gradients from failures | root_cause_hypotheses as gradients |
| **Self-Refine** [Madaan 2023] | Generate-Feedback-Refine | Critic feedback â†’ Generator â†’ Test |
| **Reflexion** [Shinn 2023] | Verbal reinforcement | Failure patterns as verbal feedback |
| **PromptWizard** [Agarwal 2024] | Instruction-Example co-optimization | Could extend to example selection |

---

## 12. Success Metrics

- **Pattern Resolution Rate**: % of FailurePatterns that reach "resolved" status
- **Prompt Improvement**: Average performance_delta of approved versions
- **Approval Rate**: % of generated variants that get approved (measures generation quality)
- **Rollback Rate**: % of activations that need rollback (should be low)
- **Time to Resolution**: Days from pattern detection to resolution

---

## 13. Scope: Prompts vs Cypher Templates

### Current Scope (Phase 5)

Phase 5 optimizes **LLM instruction prompts only**, not Cypher query templates.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  IN SCOPE: LLM Prompts              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ intent_classifier prompt         â”‚
â”‚  â€¢ search_planner prompt            â”‚
â”‚  â€¢ synthesizer prompt               â”‚
â”‚  â€¢ graph_retriever prompt           â”‚
â”‚                                     â”‚
â”‚  Location: src/agents/nodes/*.py    â”‚
â”‚  â†’ Extract to: config/prompts/      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OUT OF SCOPE: Cypher Templates     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ lookup_method                    â”‚
â”‚  â€¢ path_principle_methods           â”‚
â”‚  â€¢ comparison_impl                  â”‚
â”‚  â€¢ aggregation_* templates          â”‚
â”‚                                     â”‚
â”‚  Location: config/cypher_templates.yaml â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Rationale for Separation

| Aspect | LLM Prompts | Cypher Templates |
|--------|-------------|------------------|
| **Nature** | Natural language instructions | Structured query patterns |
| **Optimization** | Style, clarity, examples | Correctness, efficiency |
| **LLM can improve?** | Yes (text generation) | Limited (needs schema knowledge) |
| **Failure mode** | Misunderstanding, verbosity | Wrong results, syntax errors |
| **Testing** | Subjective quality scores | Deterministic result validation |

### When Retrieval Fails

If `graph_retriever` scores low, the root cause is usually:

1. **Wrong template selected** â†’ Fix `search_planner` prompt (IN SCOPE)
2. **Template itself is wrong** â†’ Manual fix to YAML (OUT OF SCOPE)
3. **Entity not in KG** â†’ Data issue, not optimization target

---

## 14. Future Extension: Cypher Template Optimization

> **Status**: Not planned for Phase 5. Consider for Phase 6+.

### Potential Approach

If we extend to Cypher optimization, it would be a **separate track**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CYPHER TEMPLATE OPTIMIZER                       â”‚
â”‚                  (Future Phase 6+)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Template        â”‚  â”‚ Template        â”‚  â”‚ Template        â”‚
â”‚ Selection       â”‚  â”‚ Correctness     â”‚  â”‚ Performance     â”‚
â”‚ Optimizer       â”‚  â”‚ Validator       â”‚  â”‚ Tuner           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                    â”‚                    â”‚
â”‚ - Which template   â”‚ - Does query      â”‚ - Index usage
â”‚   for which intent â”‚   return expected â”‚ - LIMIT values
â”‚ - Entity type      â”‚   schema?         â”‚ - Query complexity
â”‚   detection rules  â”‚ - Syntax valid?   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### Cypher-Specific Challenges

1. **Schema Awareness**: LLM needs to know node labels, relationship types, property names
2. **Syntax Validation**: Must verify Cypher is executable before testing
3. **Result Validation**: Need ground-truth expected results, not just scores
4. **Performance Metrics**: Query execution time, index usage (requires EXPLAIN/PROFILE)

### Potential CypherTemplateVersion Schema

```yaml
CypherTemplateVersion:
  id: string              # "ct:lookup_method@1.2.0"
  template_name: string   # "lookup_method"
  version: string
  cypher: string          # The actual Cypher query
  parameters: [string]    # ["entity"]
  expected_labels: [string]  # ["Method"] - for validation
  is_active: boolean
  avg_execution_time_ms: float
  created_at: datetime
```

### When to Consider This

- After Phase 5 is stable and showing value
- If retrieval failures remain high despite prompt optimization
- If new entity types/relationships are frequently added
- If query performance becomes a bottleneck
